{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 392)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load processed sorted EC clusters and raw distances\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('/home/seyonec/protein-conformal/clean_selection/sorted_dict.pkl', 'rb') as f:\n",
    "    sorted_dict = pkl.load(f)\n",
    "\n",
    "with open('/home/seyonec/protein-conformal/clean_selection/dists.pkl', 'rb') as f:\n",
    "    dists = pkl.load(f)\n",
    "\n",
    "len(sorted_dict), len(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'protein_conformal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprotein_conformal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscope_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scope_hierarchical_loss\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_clean_dict\u001b[39m(sorted_ec_dist, dists):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    sorted_ec_dist: a dictionary where each key is a query protein with EC value key,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    dists: a 2D numpy array of distances between each test protein embedding and each EC cluster center embedding\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'protein_conformal'"
     ]
    }
   ],
   "source": [
    "from protein_conformal.scope_utils import scope_hierarchical_loss\n",
    "def get_clean_dict(sorted_ec_dist, dists):\n",
    "    \"\"\"\n",
    "\n",
    "    sorted_ec_dist: a dictionary where each key is a query protein with EC value key,\n",
    "                    and each value is a dictionary of EC cluster center values and their \n",
    "                    euclidean distances to the query protein.\n",
    "\n",
    "    dists: a 2D numpy array of distances between each test protein embedding and each EC cluster center embedding\n",
    "    \"\"\"\n",
    "\n",
    "    num_train_clusters = len(dists[0])\n",
    "    near_ids = []\n",
    "    min_sim = np.min(dists)\n",
    "    max_sim = np.max(dists)\n",
    "\n",
    "    for i, key in enumerate(sorted_dict):\n",
    "        #test_id = test_df.loc[true_test_idcs[i], id]\n",
    "        test_ec = key\n",
    "        ec_cluster_centers = [k for k in sorted_ec_dist[key].keys()]\n",
    "        exact_loss = [scope_hierarchical_loss(test_ec, ec_cluster_centers[j]) for j in range(num_train_clusters)]\n",
    "        # grab the 2nd element in the tuple belonging to each element of exact_loss as mask_exact\n",
    "        mask_exact = [x[1] for x in exact_loss]\n",
    "        loss = [x[0] for x in exact_loss]\n",
    "        \n",
    "        # define mask_partial as 1 for any element of loss that is <=1 (tolerate retrieving homolog with diff family but same superfamily)\n",
    "        mask_partial = [l <= 1 for l in loss]\n",
    "\n",
    "        # create a row of size len(lookup_df) where each element is the sum of all entries in S_i until that index\n",
    "        sum = np.cumsum(dists[i])\n",
    "        norm_sim = (dists[i] - min_sim) / (max_sim - min_sim) # convert similarities into a probability space (0, 1) based on (min_sim, max_sim)\n",
    "        #mask_exact = [test_sccs == lookup_df.loc[lookup_idcs[j], 'sccs'] for j in I[i]]\n",
    "\n",
    "        sum_norm_s_i = np.cumsum(norm_sim)\n",
    "        near_ids.append({\n",
    "            'test_ec': test_ec,\n",
    "            'EC_centroids': ec_cluster_centers,\n",
    "            #'meta_query': meta_query,\n",
    "            'loss' : loss,\n",
    "            'exact': mask_exact,\n",
    "            'partial': mask_partial,\n",
    "            'S_i': dists[i],\n",
    "            'Sum_i' : sum,\n",
    "            'Norm_S_i' : norm_sim,\n",
    "            'Sum_Norm_S_i': sum_norm_s_i,\n",
    "        })\n",
    "    return near_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dict = get_clean_dict(sorted_dict, dists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
