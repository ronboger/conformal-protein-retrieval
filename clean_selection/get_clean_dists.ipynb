{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seyonec/.conda/envs/clean/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding sizes for train and test: torch.Size([241025, 128]) torch.Size([392, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5242/5242 [00:00<00:00, 27790.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating eval distance map, between 392 test ids and 5242 train EC cluster centers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [00:00, 1002.13it/s]\n",
      "100%|██████████| 5242/5242 [00:00<00:00, 38467.94it/s]\n",
      "20000it [00:15, 1292.98it/s]\n",
      "100%|██████████| 392/392 [00:09<00:00, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ EC calling results using random chosen 20k samples ############\n",
      "---------------------------------------------------------------------------\n",
      ">>> total samples: 392 | total ec: 177 \n",
      ">>> precision: 0.558 | recall: 0.477| F1: 0.482 | AUC: 0.737 \n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from CLEAN.infer import infer_pvalue\n",
    "\n",
    "test_data = \"new\"\n",
    "train_data = \"split100\"\n",
    "infer_pvalue(train_data, test_data, p_value=1e-5, nk_random=20, report_metrics=True, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seyonec/.conda/envs/clean/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Similar code to the selection methods, except we just want to extract the raw euclidean distance maps for any pair of train and test data\n",
    "import torch\n",
    "from CLEAN.utils import * \n",
    "from CLEAN.model import LayerNormNet\n",
    "from CLEAN.distance_map import *\n",
    "from CLEAN.evaluate import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "def get_eval_dist_map(train_data, test_data, pretrained=True, model_name=None):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    dtype = torch.float32\n",
    "    id_ec_train, ec_id_dict_train = get_ec_id_dict('./data/' + train_data + '.csv')\n",
    "    id_ec_test, _ = get_ec_id_dict('./data/' + test_data + '.csv')\n",
    "    # load checkpoints\n",
    "    # NOTE: change this to LayerNormNet(512, 256, device, dtype) \n",
    "    # and rebuild with [python build.py install]\n",
    "    # if inferencing on model trained with supconH loss\n",
    "    model = LayerNormNet(512, 128, device, dtype)\n",
    "    \n",
    "    if pretrained:\n",
    "        try:\n",
    "            checkpoint = torch.load('./data/pretrained/'+ train_data +'.pth', map_location=device)\n",
    "        except FileNotFoundError as error:\n",
    "            raise Exception('No pretrained weights for this training data')\n",
    "    else:\n",
    "        try:\n",
    "            checkpoint = torch.load('./data/model/'+ model_name +'.pth', map_location=device)\n",
    "        except FileNotFoundError as error:\n",
    "            raise Exception('No model found!')\n",
    "        \n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    # load precomputed EC cluster center embeddings if possible\n",
    "    if train_data == \"split70\":\n",
    "        emb_train = torch.load('./data/pretrained/70.pt', map_location=device)\n",
    "    elif train_data == \"split100\":\n",
    "        emb_train = torch.load('./data/pretrained/100.pt', map_location=device)\n",
    "    else:\n",
    "        emb_train = model(esm_embedding(ec_id_dict_train, device, dtype))\n",
    "        \n",
    "    emb_test = model_embedding_test(id_ec_test, model, device, dtype)\n",
    "    eval_dist = get_dist_map_test(emb_train, emb_test, ec_id_dict_train, id_ec_test, device, dtype)\n",
    "    seed_everything()\n",
    "\n",
    "    return eval_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding sizes for train and test: torch.Size([241025, 128]) torch.Size([392, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5242/5242 [00:00<00:00, 29275.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating eval distance map, between 392 test ids and 5242 train EC cluster centers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [00:00, 1219.90it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_dist = get_eval_dist_map(train_data, test_data, pretrained=True)\n",
    "\n",
    "true_label, all_label = get_true_labels('./data/' + test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get keys of dict as list\n",
    "test_ids = list(eval_dist.keys())\n",
    "\n",
    "# each key in the dictionary is a dictionary, and we want to sort the sub-dictionary based on the values of the keys ascending\n",
    "sorted_dict = {key: dict(sorted(eval_dist[key].items(), key=lambda item: item[1])) for key in eval_dist}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two numpy arrays, one for the keys and one for the values, of size (len(test_ids), # of keys in the sub-dictionary)\n",
    "## Go through each key in sorted_dict,\n",
    "## For each key, go through each key in the sub-dictionary and get the key value pair\n",
    "## Append the key to the keys array and the value to the values array\n",
    "import numpy as np\n",
    "\n",
    "## init 2d np arrays with 0's\n",
    "\n",
    "## np array of EC_ids (strings)\n",
    "#EC_ids = np.zeros((len(test_ids), len(sorted_dict[test_ids[0]]))\n",
    "dists = np.zeros((len(test_ids), len(sorted_dict[test_ids[0]])))\n",
    "for i, key in enumerate(sorted_dict):\n",
    "    j = 0\n",
    "    for k, v in sorted_dict[key].items():\n",
    "        dists[i][j] = v\n",
    "        j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# find first index where element dists[0] is not ascedning\n",
    "def find_non_ascending_row(arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "        if not np.all(np.diff(arr[i]) >= 0):\n",
    "            return i\n",
    "    return -1  # Return -1 if all rows are ascending\n",
    "\n",
    "# Example usage\n",
    "non_ascending_row_index = find_non_ascending_row(dists)\n",
    "print(non_ascending_row_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sorted_dict\n",
    "import pickle\n",
    "with open('/home/seyonec/protein-conformal/clean_selection/sorted_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(sorted_dict, f)\n",
    "\n",
    "# save dists\n",
    "with open('/home/seyonec/protein-conformal/clean_selection/dists.pkl', 'wb') as f:\n",
    "    pickle.dump(dists, f)\n",
    "\n",
    "# dump true labels\n",
    "with open('/home/seyonec/protein-conformal/clean_selection/true_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(true_label, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
