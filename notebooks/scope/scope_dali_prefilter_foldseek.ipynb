{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALI Prefiltering with Conformal Guarantees\n",
    "\n",
    "This notebook reproduces **Tables 4-6** from the paper:\n",
    "\"Functional protein mining with conformal guarantees\" (Nature Communications 2025)\n",
    "\n",
    "## Overview\n",
    "\n",
    "We use conformal prediction to calibrate FNR (False Negative Rate) thresholds for\n",
    "prefiltering candidates before expensive DALI structural alignment.\n",
    "\n",
    "**Key Results from Paper:**\n",
    "- TPR (True Positive Rate): ~82.8%\n",
    "- Database Reduction: ~31.5%\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "This analysis requires FoldSeek alignment scores between SCOPe test proteins and\n",
    "the lookup database. The pre-computed results are available in:\n",
    "`results/dali_thresholds.csv`\n",
    "\n",
    "For regenerating the analysis, you need:\n",
    "- `foldseek_near_ids_scope_test_v_lookup.npy` (FoldSeek scores)\n",
    "- SCOPe classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path\n",
    "repo_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f\"Repository root: {repo_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-computed DALI Results\n",
    "\n",
    "These results were computed using the Learn-then-Test (LTT) calibration procedure\n",
    "across multiple trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed results\n",
    "results_path = repo_root / \"results\" / \"dali_thresholds.csv\"\n",
    "\n",
    "if results_path.exists():\n",
    "    df = pd.read_csv(results_path)\n",
    "    print(f\"Loaded {len(df)} trials from {results_path.name}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "else:\n",
    "    print(f\"ERROR: Results not found at {results_path}\")\n",
    "    print(\"Run scripts/verify_dali.py to generate results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Key Metrics\n",
    "\n",
    "The key metrics from the paper:\n",
    "- **TPR (True Positive Rate)**: Fraction of true structural neighbors retained\n",
    "- **Database Reduction**: Fraction of database filtered out (1 - frac_samples_above_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute key metrics\n",
    "tpr_mean = df[\"TPR_elbow\"].mean() * 100\n",
    "tpr_std = df[\"TPR_elbow\"].std() * 100\n",
    "\n",
    "frac_kept = df[\"frac_samples_above_lambda\"].mean()\n",
    "db_reduction = (1 - frac_kept) * 100\n",
    "\n",
    "fnr_mean = df[\"FNR_elbow\"].mean() * 100\n",
    "fdr_mean = df[\"FDR_elbow\"].mean()\n",
    "elbow_z_mean = df[\"elbow_z\"].mean()\n",
    "elbow_z_std = df[\"elbow_z\"].std()\n",
    "\n",
    "# Paper claims\n",
    "paper_tpr = 82.8\n",
    "paper_db_reduction = 31.5\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DALI Prefiltering Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTPR (True Positive Rate): {tpr_mean:.1f}% +/- {tpr_std:.1f}%\")\n",
    "print(f\"  Paper claims: {paper_tpr}%\")\n",
    "print(f\"  Difference: {abs(tpr_mean - paper_tpr):.1f}%\")\n",
    "print(f\"\\nDatabase Reduction: {db_reduction:.1f}%\")\n",
    "print(f\"  Paper claims: {paper_db_reduction}%\")\n",
    "print(f\"  Difference: {abs(db_reduction - paper_db_reduction):.1f}%\")\n",
    "print(f\"\\nFNR (Miss Rate): {fnr_mean:.1f}%\")\n",
    "print(f\"FDR at elbow: {fdr_mean:.6f}\")\n",
    "print(f\"Elbow z-score: {elbow_z_mean:.1f} +/- {elbow_z_std:.1f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# TPR distribution\n",
    "axes[0].hist(df[\"TPR_elbow\"] * 100, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(paper_tpr, color='r', linestyle='--', label=f'Paper: {paper_tpr}%')\n",
    "axes[0].axvline(tpr_mean, color='g', linestyle='-', label=f'Mean: {tpr_mean:.1f}%')\n",
    "axes[0].set_xlabel('TPR (%)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('True Positive Rate Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Database reduction\n",
    "db_reductions = (1 - df[\"frac_samples_above_lambda\"]) * 100\n",
    "axes[1].hist(db_reductions, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(paper_db_reduction, color='r', linestyle='--', label=f'Paper: {paper_db_reduction}%')\n",
    "axes[1].axvline(db_reduction, color='g', linestyle='-', label=f'Mean: {db_reduction:.1f}%')\n",
    "axes[1].set_xlabel('Database Reduction (%)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Database Reduction Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "# Elbow z-score distribution\n",
    "axes[2].hist(df[\"elbow_z\"], bins=20, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[2].set_xlabel('Elbow z-score')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Elbow Z-score Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Summary\n",
    "\n",
    "Compare our results to the paper claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "tpr_ok = abs(tpr_mean - paper_tpr) < 2.0  # Within 2%\n",
    "db_ok = abs(db_reduction - paper_db_reduction) < 2.0  # Within 2%\n",
    "\n",
    "print(\"=\"*60)\n",
    "if tpr_ok and db_ok:\n",
    "    print(\"VERIFICATION PASSED\")\n",
    "    print(f\"  TPR {tpr_mean:.1f}% matches paper ({paper_tpr}%)\")\n",
    "    print(f\"  DB reduction {db_reduction:.1f}% matches paper ({paper_db_reduction}%)\")\n",
    "else:\n",
    "    print(\"VERIFICATION WARNING\")\n",
    "    if not tpr_ok:\n",
    "        print(f\"  TPR {tpr_mean:.1f}% differs from paper ({paper_tpr}%)\")\n",
    "    if not db_ok:\n",
    "        print(f\"  DB reduction {db_reduction:.1f}% differs from paper ({paper_db_reduction}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The conformal prefiltering approach achieves:\n",
    "- ~82% TPR while reducing the database by ~31%\n",
    "- This allows expensive DALI alignments to run on a smaller candidate set\n",
    "- Risk is controlled via the Learn-then-Test (LTT) calibration procedure\n",
    "\n",
    "For the full analysis with raw FoldSeek data, see the original notebook in `notebooks/archive/`\n",
    "or run `scripts/verify_dali.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
