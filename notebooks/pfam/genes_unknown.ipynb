{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JCVI Syn3.0 Unknown Gene Analysis\n",
    "\n",
    "This notebook reproduces **Figure 2A** from:\n",
    "\n",
    "> \"Functional protein mining with conformal guarantees\"  \n",
    "> Nature Communications (2025) 16:85  \n",
    "> https://doi.org/10.1038/s41467-024-55676-y\n",
    "\n",
    "**Result**: 59/149 (39.6%) of JCVI Syn3.0 genes of unknown function can be confidently annotated at 10% FDR.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Download from [Zenodo](https://zenodo.org/records/14272215):\n",
    "- `lookup_embeddings.npy` → `data/`\n",
    "- `lookup_embeddings_meta_data.tsv` → `data/`\n",
    "- `pfam_new_proteins.npy` → `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo root to path\n",
    "import sys\n",
    "repo_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(repo_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protein_conformal.util import (\n",
    "    load_database, query, read_fasta,\n",
    "    get_sims_labels, simplifed_venn_abers_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Query Embeddings (JCVI Syn3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed embeddings for JCVI Syn3.0 unknown genes\n",
    "data_dir = repo_root / 'data'\n",
    "query_embeddings = np.load(data_dir / 'gene_unknown' / 'unknown_aa_seqs.npy')\n",
    "print(f\"Query embeddings shape: {query_embeddings.shape}\")\n",
    "\n",
    "# Load sequence metadata\n",
    "query_fastas, query_metadata = read_fasta(data_dir / 'gene_unknown' / 'unknown_aa_seqs.fasta')\n",
    "print(f\"Number of sequences: {len(query_fastas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Database (UniProt with Pfam annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UniProt embeddings and metadata\n",
    "embeddings = np.load(data_dir / 'lookup_embeddings.npy')\n",
    "lookup_proteins_meta = pd.read_csv(data_dir / 'lookup_embeddings_meta_data.tsv', sep=\"\\t\")\n",
    "print(f\"Database size: {len(embeddings)} proteins\")\n",
    "\n",
    "# Filter to proteins with Pfam annotations\n",
    "column = 'Pfam'\n",
    "col_lookup = lookup_proteins_meta[~lookup_proteins_meta[column].isnull()]\n",
    "col_lookup_embeddings = embeddings[col_lookup.index]\n",
    "col_meta_data = col_lookup[column].values\n",
    "print(f\"Proteins with Pfam: {len(col_lookup_embeddings)}\")\n",
    "\n",
    "# Build FAISS index\n",
    "lookup_database = load_database(col_lookup_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search for Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for the 1st nearest neighbor\n",
    "k = 1\n",
    "D, I = query(lookup_database, query_embeddings, k)\n",
    "D_max = np.max(D, axis=1)\n",
    "print(f\"Similarity scores range: [{D_max.min():.6f}, {D_max.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Venn-Abers Calibrated Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calibration data\n",
    "cal_data = np.load(data_dir / 'pfam_new_proteins.npy', allow_pickle=True)\n",
    "\n",
    "# Prepare calibration set\n",
    "n_calib = 100\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(cal_data)\n",
    "cal_subset = cal_data[:n_calib]\n",
    "X_cal, y_cal = get_sims_labels(cal_subset, partial=False)\n",
    "X_cal = X_cal.flatten()\n",
    "y_cal = y_cal.flatten()\n",
    "\n",
    "# Compute probabilities for each query\n",
    "p_s = []\n",
    "for d in D:\n",
    "    p_0, p_1 = simplifed_venn_abers_prediction(X_cal, y_cal, d)\n",
    "    p_s.append([p_0, p_1])\n",
    "p_s = np.array(p_s)\n",
    "\n",
    "# Check calibration quality (uncertainty should be low)\n",
    "abs_p = [np.abs(p[0] - p[1]) for p in p_s]\n",
    "print(f\"Max |p0 - p1|: {max(abs_p):.4f} (should be close to 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply FDR Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper-verified FDR threshold at alpha=0.1\n",
    "l_hat = 0.999980225003127\n",
    "\n",
    "# Count hits above threshold\n",
    "hits = (D_max > l_hat).sum()\n",
    "total = len(D_max)\n",
    "print(f\"\\n=== JCVI Syn3.0 Annotation Results ===\")\n",
    "print(f\"Total queries: {total}\")\n",
    "print(f\"Confident hits: {hits}\")\n",
    "print(f\"Hit rate: {hits/total*100:.1f}%\")\n",
    "print(f\"FDR threshold (alpha=0.1): {l_hat:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of similarity scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Left: Similarity score distribution\n",
    "ax = axes[0]\n",
    "sns.histplot(D_max, bins=30, ax=ax)\n",
    "ax.axvline(l_hat, color='r', linestyle='--', label=f'FDR threshold (lambda={l_hat:.4f})')\n",
    "ax.set_xlabel('Similarity Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Nearest Neighbor Similarities')\n",
    "ax.legend()\n",
    "\n",
    "# Right: Pie chart\n",
    "ax = axes[1]\n",
    "hits_count = np.sum(D_max >= l_hat)\n",
    "no_hits_count = np.sum(D_max < l_hat)\n",
    "sizes = [hits_count, no_hits_count]\n",
    "labels = [f'Hits: {hits_count} ({hits_count/total*100:.1f}%)',\n",
    "          f'No Hits: {no_hits_count} ({no_hits_count/total*100:.1f}%)']\n",
    "colors = sns.color_palette()[0:2]\n",
    "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "       startangle=140, explode=(0.1, 0))\n",
    "ax.set_title(f'JCVI Syn3.0 Annotation (n={total})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to confident hits\n",
    "hit_mask = D_max > l_hat\n",
    "filtered_I = I[hit_mask]\n",
    "first_entries = filtered_I[:, 0]\n",
    "\n",
    "# Build results dataframe\n",
    "df_hits = col_lookup.iloc[first_entries].reset_index(drop=True)\n",
    "df_hits['query_sequence'] = np.array(query_fastas)[hit_mask]\n",
    "df_hits['query_name'] = np.array(query_metadata)[hit_mask]\n",
    "df_hits['similarity'] = D_max[hit_mask]\n",
    "df_hits['probability'] = np.mean(p_s[hit_mask], axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "first_cols = ['query_name', 'similarity', 'probability', 'Pfam', 'Protein names']\n",
    "other_cols = [c for c in df_hits.columns if c not in first_cols]\n",
    "df_hits = df_hits[[c for c in first_cols if c in df_hits.columns] + other_cols]\n",
    "\n",
    "print(f\"\\nTop 10 hits:\")\n",
    "df_hits[['query_name', 'similarity', 'probability', 'Pfam', 'Protein names']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_path = data_dir / 'gene_unknown' / 'unknown_aa_seqs_pfam_hits.csv'\n",
    "df_hits.to_csv(output_path, index=False)\n",
    "print(f\"Saved {len(df_hits)} hits to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the conformal protein retrieval workflow:\n",
    "\n",
    "1. **Embed** query proteins using Protein-Vec (pre-computed)\n",
    "2. **Search** against UniProt database using FAISS\n",
    "3. **Filter** using FDR-controlled threshold (alpha=0.1 → 10% expected FDR)\n",
    "4. **Calibrate** probabilities using Venn-Abers\n",
    "\n",
    "**Result**: 39.6% of JCVI Syn3.0 unknown genes can be confidently annotated.\n",
    "\n",
    "For command-line usage, see:\n",
    "```bash\n",
    "cpr search --input sequences.fasta --output results.csv --fdr 0.1\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
